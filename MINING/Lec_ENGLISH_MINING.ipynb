{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec_ENGLISH MINING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjr9U0geQooWCoVlg4l8H/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vachkim/LECTURE/blob/master/MINING/Lec_ENGLISH_MINING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaFKMljuHG9K",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 수집"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iv3o586pV7J",
        "colab_type": "text"
      },
      "source": [
        "### 1) 목적\n",
        "- [다음](https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/#10528a4e1f25)의 기사를 크롤링한다\n",
        "- BeautifulSoup를 활용해 본문 내용을 크롤링해보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-shrs8qpp5D7",
        "colab_type": "text"
      },
      "source": [
        "### 2) 모듈 다운\n",
        "- 필요한 모듈을 다운 받는다\n",
        "- requests는 url에서 데이터를 받아오기 위해 필요한 모듈이며\n",
        "- beautifulsoup는 받은 데이터에서 tag를 활용, 필요한 부분을 크롤링하기 위해 사용된다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgWehHhHpBqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLRzLp1KqHoL",
        "colab_type": "text"
      },
      "source": [
        "### 3) 텍스트 가져오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx6vPkHewfCm",
        "colab_type": "text"
      },
      "source": [
        "- 크롤링 하고 싶은 url을 입력하고 html.parser를 활용해 tag를 활성화시킨다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_-lGrgyqLEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/#10528a4e1f25'\n",
        "response = requests.get(url)\n",
        "soup = bs(response.text, 'html.parser') #request한 변수에 .text하면 text만 추출된다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpHzN6eGqXnm",
        "colab_type": "text"
      },
      "source": [
        "### 4) Tag를 통해 필요한 부분 가져오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeRvzASAwOZX",
        "colab_type": "text"
      },
      "source": [
        "- 아래와 같이 find_all을 통해 p태그를 가진 본문 내용을 가져온다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1pFGH82qa_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl = soup.find_all('p')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9r3ccgPFm7U",
        "colab_type": "text"
      },
      "source": [
        "- 선생님의 경우 아래와 같이 div에 클래스가 기사 내용을 가리키는 내용을 저장한 뒤\n",
        "- 여기에서 다시 p태그 값을 가져와 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Cj9HDnEnWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#선생님 코드\n",
        "div = soup.find('div', class_='article-body fs-article fs-responsive blah')\n",
        "p_tag = div.find_all('p')\n",
        "content = '' #빈공간의 content변수를 만든뒤\n",
        "for i in p_tag: #p tag를 가진 리스트 변수의 텍스트 부분을 content에 추가\n",
        "  content += i.text\n",
        "content[:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FYky5rYwTAP",
        "colab_type": "text"
      },
      "source": [
        "- find_all을 사용하면 위와 같이 전체 내용이 p태그를 포함한 채 리스트 형태로 나오게 된다\n",
        "- 따라서 여기에서 텍스트만 추출하고 싶으면 아래와 같이 for문을 활용, 개별적으로 text를 추출하는 것이 필요하다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt8QrTNuGwMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = []\n",
        "for line in dl:\n",
        "  txt = line.text\n",
        "  text.append(txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YxEETU-G4f2",
        "colab_type": "text"
      },
      "source": [
        "- 위와 같이 할 경우에는 전체 문자열이 리스트 형태로 저장된다\n",
        "- 하지만 마이닝은 입력값을 문자열로 받는 경우가 많기 때문에 아래와 같이 진행하는 것이 더욱 적합하다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10K3R52sq0Jz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "665b33dd-b46d-4488-df25-985f2dba79ec"
      },
      "source": [
        "#선생님 코드\n",
        "text = ''\n",
        "for line in dl:\n",
        "  text += line.text\n",
        "text[:500]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Italian Renaissance: Vitruvian Man by Leonardo da VinciIt is the present-day darling of the tech world. The current renaissance of Artificial Intelligence (AI) with its sister discipline Machine Learning (ML) has led every IT firm worth its salt to engineer some form of AI onto its platform, into its toolsets and throughout its software applications.IBM CEO Ginni Rometty has already proclaimed that AI will change 100 percent of jobs over the next decade.And yes, she does mean everybody's job fro\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ujmu9VaHNhv",
        "colab_type": "text"
      },
      "source": [
        "## 영문토큰화(Chunking)\n",
        "- 자세한 내용은 [다음](https://www.nltk.org/_modules/nltk/tokenize/punkt.html) 참조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H02ZmeQrHiEw",
        "colab_type": "text"
      },
      "source": [
        "### 1) 토큰화에 사용되는 프로그램 설치\n",
        "- Word Tokenize() = 마침표와 구두점(온점, 쉼표, 물음표 등)으로 구분해 문자열을 토큰화\n",
        "- 토큰화에 사용되는 프로그램을 설치한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng0aGWnbv4hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "29cd8af4-623c-4ff1-8f06-82b6cae970b8"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv-FX0AqIRVE",
        "colab_type": "text"
      },
      "source": [
        "- 설치한 프로그램을 import한다\n",
        "- 영문 토큰화를 위해서는 nltk.download('punkt')도 함께 입력해주어야한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JX9hndCHd7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "caa3d588-5285-4c56-c7cf-e723697128f9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt') #tokenizer를 사용하는 기준데이터이다\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVQ85VbDIaoE",
        "colab_type": "text"
      },
      "source": [
        "### 2) 기초토큰화\n",
        "- Word_Tokenizer를 활용해 앞서 불러온 text파일은 구두점을 기준으로 나눈다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viMPdxFMH94-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a7f19d2e-4322-4260-f6c2-a4724d76125d"
      },
      "source": [
        "token1 = word_tokenize(text)\n",
        "print(token1[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Italian', 'Renaissance', ':', 'Vitruvian', 'Man', 'by', 'Leonardo', 'da', 'VinciIt', 'is', 'the', 'present-day', 'darling', 'of', 'the', 'tech', 'world', '.', 'The', 'current']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukmge34eIpr5",
        "colab_type": "text"
      },
      "source": [
        "- WordPunctTokenizer를 사용하면 알파벳과 알파벳이 아닌 문자를 구분한다\n",
        "- 'present-day'로 반환되는 위의 경우와 달리 아래는 'present''-''day'로 문자열을 구분한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl9UHLagIJos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1af45858-d954-48d3-e282-67547297fb0f"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "token2 = WordPunctTokenizer().tokenize(text)\n",
        "print(token2[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Italian', 'Renaissance', ':', 'Vitruvian', 'Man', 'by', 'Leonardo', 'da', 'VinciIt', 'is', 'the', 'present', '-', 'day', 'darling', 'of', 'the', 'tech', 'world', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMedazvtJPHH",
        "colab_type": "text"
      },
      "source": [
        "- TreebankWordTokenizer는 정규표현식에 기반한 토큰화를 진행한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqT0UA7DI-ye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "0a96cd46-d820-4414-9947-187f37d19c0a"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "token3 = TreebankWordTokenizer().tokenize(text)\n",
        "print(token3[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Italian', 'Renaissance', ':', 'Vitruvian', 'Man', 'by', 'Leonardo', 'da', 'VinciIt', 'is', 'the', 'present-day', 'darling', 'of', 'the', 'tech', 'world.', 'The', 'current', 'renaissance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Viiyiub_Kkao",
        "colab_type": "text"
      },
      "source": [
        "## 품사부착(Pos-Tag)\n",
        "- 분리한 토큰에 품사를 부착한다\n",
        "- 자세한 내용은 [다음](http://www.nltk.org/api/nltk.tag.html)을 참조한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uoL-Ao5K1Nh",
        "colab_type": "text"
      },
      "source": [
        "### 1) 품사부착에 사용되는 프로그램 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hJGKtRZJfYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "dbe52bad-7657-4444-fd11-f4d76b4c083c"
      },
      "source": [
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger') #품사 부착을 위한 기준 데이터 셋"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub5OEpmDLW6O",
        "colab_type": "text"
      },
      "source": [
        "### 2) 품사부착 \n",
        "- pos_tag기능을 활용해 토큰별로 품사를 확인한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtUhMp6GLDe5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "cdc08ea8-c85d-466c-812c-90481a3ede90"
      },
      "source": [
        "taggedToken = pos_tag(token1)\n",
        "print(taggedToken[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Italian', 'JJ'), ('Renaissance', 'NNP'), (':', ':'), ('Vitruvian', 'JJ'), ('Man', 'NN'), ('by', 'IN'), ('Leonardo', 'NNP'), ('da', 'NN'), ('VinciIt', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('present-day', 'JJ'), ('darling', 'NN'), ('of', 'IN'), ('the', 'DT'), ('tech', 'JJ'), ('world', 'NN'), ('.', '.'), ('The', 'DT'), ('current', 'JJ')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8BMYSvKLLKM",
        "colab_type": "text"
      },
      "source": [
        "- Tag로 사용된 품사 약칭은 [다음](https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/)을 참조해 확인한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgyhwZ3XLcXP",
        "colab_type": "text"
      },
      "source": [
        "## 개체명 인식(Ne-Chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3TEHdy-MQPu",
        "colab_type": "text"
      },
      "source": [
        "### 1) 개체명 인식에 사용되는 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS67O4IcLKNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "5c7b0464-9c46-4e09-dd82-7501287c50bb"
      },
      "source": [
        "nltk.download('words')\n",
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pIzk20XMaqc",
        "colab_type": "text"
      },
      "source": [
        "### 2) 개체명 인식 진행\n",
        "- 단어구분과 품사 부착, 개체명 인식 순으로 마이닝을 진행한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPW1KO-8MZ7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "7e20717e-1c5d-401a-c0d0-c221c8b20be2"
      },
      "source": [
        "import nltk \n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#토큰화\n",
        "token = word_tokenize('Barack Obama likes fried chicken very much')\n",
        "print('token=', token)\n",
        "\n",
        "#품사부착\n",
        "taggedToken = pos_tag(token)\n",
        "print('pos-tag=', taggedToken)\n",
        "\n",
        "#Ne-Chunk를 통한 개체명 인식\n",
        "from nltk import ne_chunk\n",
        "neToken = ne_chunk(taggedToken)\n",
        "print(neToken)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "token= ['Barack', 'Obama', 'likes', 'fried', 'chicken', 'very', 'much']\n",
            "pos-tag= [('Barack', 'NNP'), ('Obama', 'NNP'), ('likes', 'VBZ'), ('fried', 'VBN'), ('chicken', 'JJ'), ('very', 'RB'), ('much', 'JJ')]\n",
            "(S\n",
            "  (PERSON Barack/NNP)\n",
            "  (ORGANIZATION Obama/NNP)\n",
            "  likes/VBZ\n",
            "  fried/VBN\n",
            "  chicken/JJ\n",
            "  very/RB\n",
            "  much/JJ)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO1igV_KNDHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}